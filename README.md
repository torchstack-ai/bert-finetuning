## Summary
This tutorial covers fine-tuning a BERT model to perform sentiment analysis from the Financial Tweet Sentiment Dataset.

We applied the following tools in this notebook:

* We used the HuggingFace library to perform data processing, fine-tune the BERT model, and evaluate the accuracy between the predicted class and reference.
* We benchmarked the naive BERT model and the fine-tuned BERT model, and we were able to boost performance by 17%.
* We used MLFlow for model training logging, which is a useful MLOps tool.

Follow the our blog, [The Stack](https://torchstack.ai/blogs/torchstack) for more hands-on tutorials, reviews and summaries of essential AI concepts, and what we're seeing go on in the AI space. 

You can also check out our [GitHub](https://github.com/torchstack-ai) page for more projects and code samples.  
